# Python Lexical Analyzer



A Python program for lexical analysis (tokenization) of source code files. This tool recognizes various programming language tokens, including keywords, identifiers, numbers, strings, operators, and more.

---

## Table of Contents

- [Functionality](#functionality)
- [How to Use](#how-to-use)
- [Examples](#examples)
- [License](#license)
- [Contributing](#contributing)
- [Acknowledgments](#acknowledgments)
- [Authors](#Authors)
- [Contact](#contact)
  

---

## Functionality

- **Tokenization**: The code uses regular expressions to identify and tokenize different elements in the source code, such as keywords, identifiers, numbers, strings, and operators.

- **Error Handling**: It includes error handling for lexical errors and reports them with line numbers.

- **Token Types**: Recognized tokens are categorized into different types, such as keywords, identifiers, integers, floats, strings, comments, and more.

- **Customization**: The code allows for easy customization of token patterns and can be adapted for different programming languages or dialects.

---

## How to Use

1. Clone this repository to your local machine:

   ```bash
   git clone https://github.com/nabihafaisal/Python-Lexical-Analyzer.git

## Examples

You can find example source code files in the examples directory to test the lexical analyzer with different code snippets.

## Contributing
If you have any ideas, suggestions, or contributions, please feel free to open an issue or create a pull request.
   
## Acknowledgments
libraries used to make tables is pretty tables, tools used for this is vs code.

## Authors of this project
nabiha faisal
khadeeja arshad ali

## Contact
nabiha faisal
GitHub: https://github.com/nabihafaisal
Email: nabihfaisal@gmail.com

